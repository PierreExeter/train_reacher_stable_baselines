
# pre trained agents: work OK
python enjoy.py --algo sac --env ReacherBulletEnv-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo ppo2 --env ReacherBulletEnv-v0 --folder trained_agents/ -n 5000



# train agent myself
python train.py --algo ppo2 --env ReacherBulletEnv-v0 --eval-freq 10000 --eval-episodes 10 --save-freq 100000
python train.py --algo ppo2 --env Reacher2Dof-v0 --eval-freq 10000 --eval-episodes 10 --save-freq 100000
python train.py --algo sac --env ReacherBulletEnv-v0 --eval-freq 10000 --eval-episodes 10 --save-freq 100000


# enjoy agent trained by myself


1500 time steps because one episode last for 150 time steps and I want to evaluate for 10 episodes

python enjoy.py --algo ppo2 --env ReacherBulletEnv-v0 -f logs/ --exp-id 0 -n 1500
python enjoy.py --algo ppo2 --env ReacherBulletEnv-v0 -f logs/ --exp-id 0 -n 1500

python enjoy.py --algo ppo2 --env Reacher2Dof-v0 -f logs/ --exp-id 0 -n 1500




------------ PENDULUM-V0------------

# enjoy pre trained agents
python enjoy.py --algo a2c --env Pendulum-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo acktr --env Pendulum-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo ppo2 --env Pendulum-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo ddpg --env Pendulum-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo sac --env Pendulum-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo td3 --env Pendulum-v0 --folder trained_agents/ -n 5000
python enjoy.py --algo trpo --env Pendulum-v0 --folder trained_agents/ -n 5000


# optimise hyperparameters
python train.py --algo a2c --env Pendulum-v0 -n 100000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo acktr --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo ppo2 --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo ddpg --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo sac --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo td3 --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo ppo2 --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median
python train.py --algo trpo --env Pendulum-v0 -n 10000 -optimize --n-trials 100 --n-jobs -1 --sampler tpe --pruner median


# train agent myself
python train.py --algo a2c --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0
python train.py --algo acktr --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0
python train.py --algo ppo2 --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0
python train.py --algo ddpg --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0
python train.py --algo sac --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0
python train.py --algo td3 --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0
python train.py --algo trpo --env Pendulum-v0 -n 10000 --eval-freq 10000 --eval-episodes 10 --save-freq 100000 --seed 0



# train with seeds
# see run_experiments_pendulum.sh


# enjoy agent trained by myself
python enjoy.py --algo a2c --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000
python enjoy.py --algo acktr --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000
python enjoy.py --algo ppo2 --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000
python enjoy.py --algo ddpg --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000
python enjoy.py --algo sac --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000
python enjoy.py --algo td3 --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000
python enjoy.py --algo trpo --env Pendulum-v0 -f logs/ --exp-id 0 --no-render -n 2000



# plot learning curve and compute training stats
plot_results.py   # change log dir



# evaluate an exeriment 
# eval for 100 episodes


python enjoy.py --algo a2c --env Pendulum-v0 -f logs/a2c/Pendulum-v0_Env_1/ --exp-id 1 --no-render -n 20000
python plot_results.py -f logs/a2c/Pendulum-v0_Env_1/a2c/Pendulum-v0_1/

./get_results_exp.sh
python plot_experiment.py -f logs/a2c/Pendulum-v0_Env_1/a2c/







